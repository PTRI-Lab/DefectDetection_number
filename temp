import cv2
import numpy as np
import easyocr
import re
import time
from collections import Counter
import base64

# 初始化 EasyOCR
# 支援英文，可以根據需要添加其他語言，例如 ['en', 'ch_sim'] 支援中英文
ocr_reader = easyocr.Reader(['en'], gpu=True)  # 設置gpu=False如果沒有GPU

conf_threshold = 0.5
frame_count = 0
start_time = time.time()
last_ocr_time = 0
text_counter = Counter()
text_conf_dict = {}  # 記錄每個文字最高 confidence和座標
serial_number = 1
out_of_area = True  # 一開始假設不在檢測區
defect_margin = 30  # 邊界緩衝
last_roi_image = None  # 保存最後一次的ROI圖像
OCR_INTERVAL = 1 # 每幾偵做一次OCR
# 標準化尺寸
STANDARD_WIDTH = 320 #400
STANDARD_HEIGHT = 240 #300

# 中間線位置設定（可調整）
# 0.5 = 畫面正中央, 0.6 = 偏右, 0.4 = 偏左
LINE_POSITION_RATIO = 0.4  # 調整這個值來改變線的位置


def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.linalg.norm(br - bl)
    widthB = np.linalg.norm(tr - tl)
    maxWidth = int(max(widthA, widthB))
    heightA = np.linalg.norm(tr - br)
    heightB = np.linalg.norm(tl - bl)
    maxHeight = int(max(heightA, heightB))
    if maxWidth <= 0 or maxHeight <= 0:
        return None
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    return warped

def normalize_image_size(image, target_width=STANDARD_WIDTH, target_height=STANDARD_HEIGHT):
    """將圖片標準化到指定尺寸"""
    if image is None:
        return None
    return cv2.resize(image, (target_width, target_height))

def easyocr_bbox_to_minmax(bbox_points):
    """將EasyOCR的bbox點轉換為[x_min, y_min, x_max, y_max]格式"""
    # EasyOCR返回的bbox格式是 [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
    x_coords = [point[0] for point in bbox_points]
    y_coords = [point[1] for point in bbox_points]
    return [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]

def normalize_bbox_coordinates(bbox, original_width, original_height, target_width=STANDARD_WIDTH, target_height=STANDARD_HEIGHT):
    """將bbox座標從原始尺寸正規化到目標尺寸"""
    x_min, y_min, x_max, y_max = bbox
    
    # 計算縮放比例
    scale_x = target_width / original_width
    scale_y = target_height / original_height
    
    # 正規化座標
    normalized_bbox = [
        int(x_min * scale_x),
        int(y_min * scale_y),
        int(x_max * scale_x),
        int(y_max * scale_y)
    ]
    
    return normalized_bbox

def run_ocr_and_collect_text(warped_img, conf_threshold=0.5):                
    results = {}
    try:
        # EasyOCR的readtext方法返回 (bbox, text, confidence)
        ocr_results = ocr_reader.readtext(warped_img)
        for (bbox, text, confidence) in ocr_results:
            if confidence >= conf_threshold:
                print(f"🔍 原始OCR文字: '{text}' (confidence: {confidence:.3f})")
                # 修改：將非字母數字字符替換為空白，然後移除空白
                clean_text = re.sub(r'[^A-Za-z0-9]', '', text.replace(' ', ''))
                print(f"✨ 清理後文字: '{clean_text}'")
                if clean_text:
                    text_counter[clean_text] += 1
                    text_conf_dict[clean_text] = max(text_conf_dict.get(clean_text, 0.0), float(confidence))
                    results[clean_text] = {
                        "score": float(confidence),
                        "bbox": easyocr_bbox_to_minmax(bbox)
                    }
    except Exception as e:
        print("OCR error on warped:", e)
    return results

def image_to_base64(image):
    """将OpenCV图像转换为base64字符串"""
    try:
        # 将图像编码为JPEG格式
        _, buffer = cv2.imencode('.jpg', image)
        # 转换为base64字符串
        image_base64 = base64.b64encode(buffer).decode('utf-8')
        return image_base64
    except Exception as e:
        print(f"Error converting image to base64: {e}")
        return ""

def calculate_iou(current_warped_img, current_text, threshold=0.9):
    """
    計算當前圖片與標準答案的 IoU
    - current_warped_img: 當前 warped ROI
    - current_text: 當前檢測到的文字
    - threshold: IoU 閾值
    """
    global reference_warped_img, reference_text, reference_bbox
    try:
        if reference_warped_img is None or reference_bbox is None:
            print("❌ Reference 尚未正確載入，無法計算 IoU")
            return 0.0, False

        # 只對 current warped 做 OCR
        curr_normalized = cv2.resize(current_warped_img, (STANDARD_WIDTH, STANDARD_HEIGHT))
        curr_ocr_results = ocr_reader.readtext(curr_normalized)

        curr_bbox = None
        for (bbox, text, confidence) in curr_ocr_results:
            clean_text = re.sub(r'[^A-Za-z0-9]', '', text.replace(' ', ''))
            if clean_text == current_text:
                curr_bbox = easyocr_bbox_to_minmax(bbox)
                break

        if curr_bbox is None:
            print(f"❌ 當前圖片無法找到文字 '{current_text}' 的座標")
            return 0.0, False

        # 計算 IoU
        box1, box2 = reference_bbox, curr_bbox
        x1, y1 = max(box1[0], box2[0]), max(box1[1], box2[1])
        x2, y2 = min(box1[2], box2[2]), min(box1[3], box2[3])

        if x2 < x1 or y2 < y1:
            print(f"📦 無重疊: ref={box1}, curr={box2}")
            return 0.0, False

        intersection = (x2 - x1) * (y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection

        iou = intersection / union if union > 0 else 0.0
        is_aligned = iou >= threshold

        print(f"📏 IoU={iou:.3f}, 對齊={'✅' if is_aligned else '❌'}")
        return iou, is_aligned

    except Exception as e:
        print(f"❌ calculate_iou error: {e}")
        return 0.0, False

# 全局變數存儲標準答案圖片和文字
reference_warped_img = None
reference_text = None
reference_bbox = None  # <--- 紀錄標準答案文字的bbox

# 當前檢測會話的位置記錄
current_session_position_checked = False
current_session_position_status = "clear"
current_session_warped_img = None

# 追蹤矩形是否跨越中間線
rect_crossed_line = False
last_rect_x = None  # 記錄上一幀矩形的x座標

def load_reference_image(ref_path):
    """載入標準答案圖片並記錄 warped 圖片、文字和 bbox"""
    global reference_warped_img, reference_text, reference_bbox

    try:
        ref_image = cv2.imread(ref_path)
        if ref_image is None:
            print(f"❌ Cannot load reference image: {ref_path}")
            return False

        # 找矩形輪廓
        ref_gray = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(ref_gray, (5, 5), 0)
        edges = cv2.Canny(blur, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        max_area = 0
        best_approx = None
        for cnt in contours:
            peri = cv2.arcLength(cnt, True)
            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
            area = cv2.contourArea(approx)

            if len(approx) == 4 and area > 5000:
                if area > max_area:
                    max_area = area
                    best_approx = approx.reshape(4, 2).astype(np.float32)

        if best_approx is None:
            print("❌ Cannot find rectangle in reference image")
            return False

        # 透視變換
        ref_warped = four_point_transform(ref_image, best_approx)
        if ref_warped is None:
            print("❌ Perspective transform failed")
            return False

        print(f"📐 標準圖透視變換後尺寸: {ref_warped.shape[:2]}")

        # 保存 warped 圖片
        reference_warped_img = ref_warped.copy()

        # OCR 一次，取第一個文字 + bbox
        ocr_texts = run_ocr_and_collect_text(ref_warped, conf_threshold)
        if len(ocr_texts) > 0:
            reference_text = list(ocr_texts.keys())[0]
            reference_bbox = list(ocr_texts.values())[0]["bbox"]  # <--- 儲存標準 bbox
            print(f"📍 標準答案文字: '{reference_text}', bbox={reference_bbox}")
            return True
        else:
            print("❌ Reference image OCR 沒有找到文字")
            return False

    except Exception as e:
        print(f"❌ Error loading reference image: {e}")
        import traceback
        traceback.print_exc()
        return False
        
# 載入標準答案
reference_image_path = r"./reference3.jpg"  # 請修改為你的標準答案圖片路徑
reference_loaded = load_reference_image(reference_image_path)
print(f"✅ Reference image loaded: {reference_loaded}")
if reference_loaded:
    print(f"📝 Reference text: '{reference_text}'")

# 影片讀取
video_path = r"./sample3.mp4"
cap = cv2.VideoCapture("sample3.mp4")
if not cap.isOpened():
    print("❌ Cannot open video")
    exit()


while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_count += 1
    elapsed_time = time.time() - start_time
    fps = frame_count / elapsed_time if elapsed_time > 0 else 0
    height, width = frame.shape[:2]
    line_x = int(width * LINE_POSITION_RATIO)  # 計算線的x座標

    #⭐ findContours 前先縮小畫面
    right_half = frame[:, line_x:].copy()
    small = cv2.resize(right_half, (right_half.shape[1]//2, right_half.shape[0]//2))
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (3, 3), 0)
    edges = cv2.Canny(blur, 100, 200)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    max_area = 0
    best_rect = None
    best_approx = None
    for cnt in contours:
        cnt = cnt * 2  # ⭐ 座標放大回來
        peri = cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
        if len(approx) == 4:
            area = cv2.contourArea(approx)
            if area > 5000:
                x, y, w, h = cv2.boundingRect(approx)
                aspect_ratio = w / float(h) if h != 0 else 0
                if 0.3 < aspect_ratio < 3.0 and area > max_area:
                    max_area = area
                    best_approx = approx.reshape(4, 2).astype(np.float32)
                    best_rect = (x, y, w, h)

    if best_rect is not None:
        x, y, w, h = best_rect
        rect_center_x = x + w / 2
        rect_center_y = y + h / 2

        defect_x_min = defect_margin
        defect_x_max = right_half.shape[1] - defect_margin
        defect_y_min = defect_margin
        defect_y_max = right_half.shape[0] - defect_margin

        inside_area = (
            defect_x_min <= rect_center_x <= defect_x_max and
            defect_y_min <= rect_center_y <= defect_y_max
        )

        # 檢查矩形是否跨越中間線（從右側進入左側）
        rect_center_x_in_full_frame = x + line_x + w/2  # 矩形中心在完整畫面中的x座標
        
        # 檢測跨越中間線的邏輯
        if last_rect_x is not None:
            # 如果矩形從右側（x > line_x）移動到左側（x <= line_x），表示跨越了中間線
            if last_rect_x > line_x and rect_center_x_in_full_frame <= line_x:
                rect_crossed_line = True
                text_counter = Counter()
                text_conf_dict.clear()
                # 重置當前會話的位置檢查狀態
                current_session_position_checked = False
                current_session_position_status = "clear"
                current_session_warped_img = None
                #print("🚀 矩形跨越中間線 → 重置計數器和位置狀態")
                out_of_area = False
        
        # 更新上一幀的矩形位置
        last_rect_x = rect_center_x_in_full_frame

        if inside_area:
            if out_of_area and not rect_crossed_line:
                # 只有在非跨越中間線的情況下，重新進入檢測區才重置
                text_counter = Counter()
                text_conf_dict.clear()
                # 重置當前會話的位置檢查狀態
                current_session_position_checked = False
                current_session_position_status = "clear"
                current_session_warped_img = None
                #print("📄 重新進入檢測區域 → 重置計數器和位置狀態")
            out_of_area = False
            rect_crossed_line = False  # 重置跨越標記
        else:
            # 仍在畫面但超出 defect area 不重置，等消失再處理
            pass

        warped = None
        #print(f"🔍 檢測到矩形: x={x}, y={y}, w={w}, h={h}")
        #print(f"📏 right_half尺寸: {right_half.shape}")
        
        if best_approx is not None:
            #print(f"🔶 使用透視變換，矩形點: {best_approx}")
            warped = four_point_transform(right_half, best_approx)
            if warped is None:
                #print("⚠️ 透視變換失敗，使用邊界框裁切")
                # 確保裁切範圍在圖像邊界內
                y_start = max(0, y)
                y_end = min(right_half.shape[0], y + h)
                x_start = max(0, x)
                x_end = min(right_half.shape[1], x + w)
                #print(f"📐 邊界框裁切範圍: x={x_start}:{x_end}, y={y_start}:{y_end}")
                warped = right_half[y_start:y_end, x_start:x_end].copy()
            #else:
               # print(f"✅ 透視變換成功，結果尺寸: {warped.shape}")
        else:
            #print("🔳 使用邊界框裁切")
            # 確保裁切範圍在圖像邊界內
            y_start = max(0, y)
            y_end = min(right_half.shape[0], y + h)
            x_start = max(0, x)
            x_end = min(right_half.shape[1], x + w)
            #print(f"📐 邊界框裁切範圍: x={x_start}:{x_end}, y={y_start}:{y_end}")
            warped = right_half[y_start:y_end, x_start:x_end].copy()
        
        # 檢查warped圖像是否有效
        if warped is not None and warped.size > 0:
            print(f"✅ Warped圖像有效，尺寸: {warped.shape}")
        else:
            print("❌ Warped圖像無效，跳過OCR")
            if warped is not None:
                print(f"   圖像大小: {warped.size}")
            warped = None

        # 只有在warped圖像有效時才進行OCR和顯示
        if warped is not None and frame_count % OCR_INTERVAL == 0:
           current_ocr_texts = run_ocr_and_collect_text(warped, conf_threshold)
        else:
            current_ocr_texts = {}
        
        # 檢查是否需要進行位置檢測（只在第一次檢測到文字且有標準答案時進行）
        if (not current_session_position_checked and 
            current_ocr_texts and 
            reference_warped_img is not None and 
            reference_text is not None):
            
            # 取得當前檢測到的第一個文字進行位置檢查
            first_detected_text = list(current_ocr_texts.keys())[0]
            #print(f"🎯 首次檢測到文字 '{first_detected_text}'，進行位置檢查...")
            
            iou_value, is_aligned = calculate_iou(
                warped, 
                first_detected_text, 
                threshold=0.6
            )
            
            current_session_position_status = "clear" if is_aligned else "misaligned"
            current_session_position_checked = True
            current_session_warped_img = warped.copy()  # 保存這一幀的圖片
            
            #print(f"✅ 位置檢查完成: IoU={iou_value:.3f}, Status={current_session_position_status}")
            #print("💡 本次會話不再重複進行位置檢查")

        # 顯示ROI窗口（只有在warped有效時）
        if warped is not None and warped.size > 0:
            roi_display = warped.copy()
            if current_ocr_texts:
                # 顯示清理後的文字（current_ocr_texts.keys() 已經是清理過的）
                cleaned_texts = list(current_ocr_texts.keys())
                text_line = " ".join(cleaned_texts)
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.8
                font_thickness = 2
                (text_width, text_height), baseline = cv2.getTextSize(text_line, font, font_scale, font_thickness)
                padding = 10
                cv2.rectangle(roi_display, (0, 0), (roi_display.shape[1], text_height + padding * 2), (255, 255, 255), -1)
                cv2.rectangle(roi_display, (0, 0), (roi_display.shape[1], text_height + padding * 2), (0, 0, 0), 2)
                cv2.putText(roi_display, text_line, (padding, text_height + padding),
                            font, font_scale, (0, 0, 0), font_thickness)
            
            # 保存包含OCR文本叠加的標準化ROI圖像
            last_roi_image = roi_display.copy()
            cv2.imshow("ROI + OCR Compare", roi_display)

        if best_approx is not None:
            pts_int = best_approx.astype(int)
            pts_int[:, 0] += line_x  # 調整座標偏移
            cv2.polylines(frame, [pts_int], True, (255, 0, 0), 2)
        else:
            cv2.rectangle(frame, (x + line_x, y), (x + line_x + w, y + h), (255, 0, 0), 2)

        top3 = text_counter.most_common(3)
        y0 = 30
        for i, (word, count) in enumerate(top3):
            y = y0 + i * 30
            cv2.putText(frame, f"{word}: {count}", (10, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    else:
        # 沒有找到矩形 → 視為離開
        last_rect_x = None  # 重置位置追蹤
        
        if not out_of_area:
            # 在離開前輸出 JSON
            if text_counter:
                top1, count = text_counter.most_common(1)[0]
                confidence = text_conf_dict.get(top1, 0.0)
                
                # 使用已經檢查過的位置狀態
                position_status = current_session_position_status
                #print(f"📋 使用已記錄的位置狀態: {position_status}")
                
                # 將最後的ROI圖像轉換為base64（優先使用位置檢查時保存的圖片）
                image_base64 = ""
                roi_image_to_save = current_session_warped_img if current_session_warped_img is not None else last_roi_image
                if roi_image_to_save is not None:
                    image_base64 = image_to_base64(roi_image_to_save)

                result_json = {
                    serial_number: {
                        "value": top1,
                        "confidence": round(confidence, 3),
                        "status": position_status,
                        #"bbox": current_bbox,  # 添加座標資訊
                        "image_base64": "none" #image_base64
                    }
                }
                print("📤 JSON result:", result_json)
                serial_number += 1

            #print("⬅️ Lost detection → mark as out of area")
            out_of_area = True

    # 畫檢測區框線
    cv2.line(frame, (line_x, 0), (line_x, height), (0, 255, 255), 2)

    cv2.putText(frame, f"Frame: {frame_count}", (10, 120),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    cv2.putText(frame, f"FPS: {fps:.2f}", (10, 150),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

    cv2.imshow("Frame", frame)

    key = cv2.waitKey(1) & 0xFF
    if key == ord("q"):
        break
    elif key == ord("a"):  # 向左移動線
        LINE_POSITION_RATIO = max(0.1, LINE_POSITION_RATIO - 0.05)
        print(f"📍 線位置調整為: {LINE_POSITION_RATIO:.2f} (向左)")
    elif key == ord("d"):  # 向右移動線
        LINE_POSITION_RATIO = min(0.9, LINE_POSITION_RATIO + 0.05)
        print(f"📍 線位置調整為: {LINE_POSITION_RATIO:.2f} (向右)")

cap.release()
cv2.destroyAllWindows()
